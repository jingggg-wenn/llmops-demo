apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: llmops-dev

namePrefix: dev-
nameSuffix: ""

resources:
  - ../../base

patches:
  - target:
      kind: InferenceService
      name: qwen25-05b-instruct
    patch: |-
      - op: replace
        path: /metadata/annotations/openshift.io~1display-name
        value: "qwen2.5-0.5b-dev-v1"
      - op: replace
        path: /spec/predictor/model/runtime
        value: "dev-qwen25-05b-instruct"
      - op: replace
        path: /spec/predictor/minReplicas
        value: 1
      - op: replace
        path: /spec/predictor/maxReplicas
        value: 1
      - op: replace
        path: /spec/predictor/model/resources/limits/cpu
        value: "2"
      - op: replace
        path: /spec/predictor/model/resources/limits/memory
        value: "6Gi"
      - op: replace
        path: /spec/predictor/model/resources/requests/cpu
        value: "500m"
      - op: replace
        path: /spec/predictor/model/resources/requests/memory
        value: "4Gi"
  # Patch ServingRuntime to reduce max-model-len for staging testing
  - target:
      kind: ServingRuntime
      name: qwen25-05b-instruct
    patch: |-
      - op: replace
        path: /spec/containers/0/args/4
        value: "12000"

